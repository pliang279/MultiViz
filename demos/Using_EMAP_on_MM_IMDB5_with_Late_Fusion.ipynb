{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using EMAP on MM-IMDB5 with Late Fusion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSSZolCI72Ps"
      },
      "source": [
        "# !wget https://archive.org/download/mmimdb/multimodal_imdb.hdf5"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dro0kswSAs72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f646faa4-5400-4ea1-8abd-502a9efb9681"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtISdxz7-9fN"
      },
      "source": [
        "# !cp multimodal_imdb.hdf5 /content/drive/MyDrive/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0BYR5WpMxaV"
      },
      "source": [
        "# !cp /content/drive/MyDrive/multimodal_imdb.hdf5 ./"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg6lwgK_Dv23",
        "outputId": "103b55ea-adfe-47c1-fa68-01f40d78ed31"
      },
      "source": [
        "!git clone https://www.github.com/pliang279/MultiBench.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MultiBench' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfr3Rr29FXzd",
        "outputId": "406a351d-19b4-47fa-d9e8-68e67c4859ce"
      },
      "source": [
        "!pip install memory_profiler"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.7/dist-packages (0.58.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Tmete2LD0Kt",
        "outputId": "4f838424-7924-45da-a2f1-d1ba23e8c823"
      },
      "source": [
        "%%writefile /content/MultiBench/datasets/imdb/get_data.py\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from typing import *\n",
        "import numpy as np\n",
        "\n",
        "# sys.path.append('/content/datasets/imdb/')\n",
        "# from robustness.visual_robust import visual_robustness\n",
        "# from robustness.text_robust import text_robustness\n",
        "\n",
        "# from .vgg import VGGClassifier\n",
        "# from gensim.models import KeyedVectors\n",
        "\n",
        "import h5py\n",
        "from typing import *\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import json\n",
        "from PIL import Image\n",
        "from typing import *\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, file:h5py.File, start_ind:int, end_ind:int, vggfeature:bool=False) -> None:\n",
        "        self.file = file\n",
        "        self.start_ind = start_ind\n",
        "        self.size = end_ind-start_ind\n",
        "        self.vggfeature = vggfeature\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        if not hasattr(self, 'dataset'):\n",
        "            self.dataset = h5py.File(self.file, 'r')\n",
        "        text = self.dataset[\"features\"][ind+self.start_ind]\n",
        "        image = self.dataset[\"images\"][ind+self.start_ind] if not self.vggfeature else \\\n",
        "            self.dataset[\"vgg_features\"][ind+self.start_ind]\n",
        "        label = self.dataset[\"genres\"][ind+self.start_ind]\n",
        "\n",
        "        return text, image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "class IMDBDataset_robust(Dataset):\n",
        "    \n",
        "    def __init__(self, dataset, start_ind:int, end_ind:int) -> None:\n",
        "        self.dataset = dataset\n",
        "        self.start_ind = start_ind\n",
        "        self.size = end_ind-start_ind\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        text = self.dataset[ind+self.start_ind][0]\n",
        "        image = self.dataset[ind+self.start_ind][1]\n",
        "        label = self.dataset[ind+self.start_ind][2]\n",
        "\n",
        "        return text, image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "def process_data(filename, path):\n",
        "    data = {}\n",
        "    filepath = os.path.join(path, filename)\n",
        "\n",
        "    with Image.open(filepath+\".jpeg\") as f:\n",
        "        image = np.array(f.convert(\"RGB\"))\n",
        "        data[\"image\"] = image\n",
        "    \n",
        "    with open(filepath+\".json\", \"r\") as f:\n",
        "        info = json.load(f)\n",
        "        \n",
        "        plot = info[\"plot\"]\n",
        "        data[\"plot\"] = plot\n",
        "\n",
        "    return data\n",
        "\n",
        "def get_dataloader(path:str,num_workers:int=8, train_shuffle:bool=True, batch_size:int=40, vgg:bool=False, skip_process=False)->Tuple[Dict]:\n",
        "    train_dataloader = DataLoader(IMDBDataset(path, 0, 15552, vgg), shuffle=train_shuffle, num_workers=num_workers, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(IMDBDataset(path, 15552, 18160, vgg), shuffle=False, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "    # test_dataset = h5py.File(path, 'r')\n",
        "    # test_text = test_dataset['features'][18160:25959]\n",
        "    # test_vision = test_dataset['vgg_features'][18160:25959]\n",
        "    # labels = test_dataset[\"genres\"][18160:25959]\n",
        "    # names = test_dataset[\"imdb_ids\"][18160:25959]\n",
        "    \n",
        "    # dataset = os.path.join(test_path, \"dataset\")\n",
        "\n",
        "    # if not skip_process:\n",
        "    #     clsf = VGGClassifier(model_path='/home/pliang/multibench/MultiBench/datasets/imdb/vgg16.tar', synset_words='synset_words.txt')\n",
        "    #     googleword2vec = KeyedVectors.load_word2vec_format('/home/pliang/multibench/MultiBench/datasets/imdb/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "        \n",
        "    #     images = []\n",
        "    #     texts = []\n",
        "    #     for name in tqdm(names):\n",
        "    #         name = name.decode(\"utf-8\")\n",
        "    #         data = process_data(name, dataset)\n",
        "    #         images.append(data['image'])\n",
        "    #         plot_id = np.array([len(p) for p in data['plot']]).argmax()\n",
        "    #         texts.append(data['plot'][plot_id])\n",
        "    \n",
        "    # Add visual noises\n",
        "    # robust_vision = []\n",
        "    # for noise_level in range(11):\n",
        "    #     vgg_filename = os.path.join(os.getcwd(), 'vgg_features_{}.npy'.format(noise_level))\n",
        "    #     if not skip_process:\n",
        "    #         vgg_features = []\n",
        "    #         images_robust = visual_robustness(images, noise_level=noise_level/10)\n",
        "    #         for im in tqdm(images_robust):\n",
        "    #             vgg_features.append(clsf.get_features(Image.fromarray(im)).reshape((-1,)))\n",
        "    #         np.save(vgg_filename, vgg_features)\n",
        "    #     else:\n",
        "    #         assert os.path.exists(vgg_filename) == True\n",
        "    #         vgg_features = np.load(vgg_filename, allow_pickle=True)\n",
        "    #     robust_vision.append([(test_text[i], vgg_features[i], labels[i]) for i in range(len(vgg_features))])\n",
        "    \n",
        "    # test_dataloader = dict()\n",
        "    # test_dataloader['image'] = []\n",
        "    # for test in robust_vision:\n",
        "    #     test_dataloader['image'].append(DataLoader(IMDBDataset_robust(test, 0, len(test)), shuffle=False, num_workers=num_workers, batch_size=batch_size))\n",
        "\n",
        "    # Add text noises\n",
        "    # robust_text = []\n",
        "    # for noise_level in range(11):\n",
        "    #     text_filename = os.path.join(os.getcwd(), 'text_features_{}.npy'.format(noise_level)) \n",
        "    #     if not skip_process:\n",
        "    #         text_features = []\n",
        "    #         texts_robust = text_robustness(texts, noise_level=noise_level/10)    \n",
        "    #         for words in tqdm(texts_robust):\n",
        "    #             words = words.split()\n",
        "    #             if len([googleword2vec[w] for w in words if w in googleword2vec]) == 0:\n",
        "    #                 text_features.append(np.zeros((300,)))\n",
        "    #             else:\n",
        "    #                 text_features.append(np.array([googleword2vec[w] for w in words if w in googleword2vec]).mean(axis=0))\n",
        "    #         np.save(text_filename, text_features)\n",
        "    #     else:\n",
        "    #         assert os.path.exists(text_filename) == True\n",
        "    #         text_features = np.load(text_filename, allow_pickle=True)\n",
        "    #     robust_text.append([(text_features[i], test_vision[i], labels[i]) for i in range(len(text_features))])\n",
        "    # test_dataloader['text'] = []\n",
        "    # for test in robust_text:\n",
        "    #     test_dataloader['text'].append(DataLoader(IMDBDataset_robust(test, 0, len(test)), shuffle=False, num_workers=num_workers, batch_size=batch_size))\n",
        "    return train_dataloader, val_dataloader"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/MultiBench/datasets/imdb/get_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uYLNOfiEaic",
        "outputId": "edaa1154-f5c2-44e3-a8bb-65f9b3d12827"
      },
      "source": [
        "%cd MultiBench"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MultiBench\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjHSENd3HrXq"
      },
      "source": [
        "import h5py\n",
        "test_dataset = h5py.File(\"/content/drive/MyDrive/multimodal_imdb.hdf5\", 'r')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPMRKsYUUEY2",
        "outputId": "6e81739e-d5d5-4428-8bdd-7e19bf169b8e"
      },
      "source": [
        "test_dataset.keys()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KeysViewHDF5 ['features', 'genres', 'images', 'imdb_ids', 'sequences', 'three_grams', 'vgg_features', 'word_grams']>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE9E6k75A7mf",
        "outputId": "4ae355c4-8c45-4fb4-9d95-268388b19fc8"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from training_structures.Supervised_Learning import train, test\n",
        "from fusions.common_fusions import Concat\n",
        "from datasets.imdb.get_data import get_dataloader\n",
        "from unimodals.common_models import Linear, MaxOut_MLP\n",
        "\n",
        "traindata, validdata = get_dataloader(\"/content/drive/MyDrive/multimodal_imdb.hdf5\", skip_process=True, vgg=True, batch_size=128)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIos1f07EkFv",
        "outputId": "b3b47172-9eb5-4da5-a296-46632004b889"
      },
      "source": [
        "encoders=[MaxOut_MLP(512, 512, 300, linear_layer=False), MaxOut_MLP(512, 1024, 4096, 512, False)]\n",
        "head= Linear(1024, 23).cuda()\n",
        "fusion=Concat().cuda()\n",
        "\n",
        "filename = \"best_lf.pt\"\n",
        "\n",
        "train(encoders,fusion,head,traindata,validdata,1000, early_stop=True,task=\"multilabel\",\\\n",
        "    save=filename, optimtype=torch.optim.AdamW,lr=8e-3,weight_decay=0.01, objective=torch.nn.BCEWithLogitsLoss())\n",
        "\n",
        "# print(\"Testing:\")\n",
        "# test(model,testdata,method_name=\"lf\",dataset=\"imdb\",criterion=torch.nn.BCEWithLogitsLoss(),task=\"multilabel\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: tensor(0.2068, device='cuda:0') f1_micro: 0.5760802604945877 f1_macro: 0.4424341473151621\n",
            "Saving Best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train loss: tensor(0.1960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: tensor(0.1950, device='cuda:0') f1_micro: 0.5746980292434839 f1_macro: 0.4534234583888036\n",
            "Saving Best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train loss: tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: tensor(0.1937, device='cuda:0') f1_micro: 0.5915075420699276 f1_macro: 0.49470319411848096\n",
            "Saving Best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train loss: tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: tensor(0.1971, device='cuda:0') f1_micro: 0.5883193427397749 f1_macro: 0.4973879100331768\n",
            "Saving Best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train loss: tensor(0.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: tensor(0.2077, device='cuda:0') f1_micro: 0.5850000000000001 f1_macro: 0.47701555105164845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train loss: tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: tensor(0.2190, device='cuda:0') f1_micro: 0.5891891891891892 f1_macro: 0.5109817837348082\n",
            "Saving Best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train loss: tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: tensor(0.2361, device='cuda:0') f1_micro: 0.5794520547945207 f1_macro: 0.5031924285316908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train loss: tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: tensor(0.2645, device='cuda:0') f1_micro: 0.5840578532542456 f1_macro: 0.49927568530945504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train loss: tensor(0.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: tensor(0.2849, device='cuda:0') f1_micro: 0.5823761076468658 f1_macro: 0.4955320323521612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train loss: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: tensor(0.3035, device='cuda:0') f1_micro: 0.5778698715292168 f1_macro: 0.49670001043923867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train loss: tensor(0.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: tensor(0.3209, device='cuda:0') f1_micro: 0.5781326380967899 f1_macro: 0.49945978218598575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 train loss: tensor(0.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: tensor(0.3375, device='cuda:0') f1_micro: 0.5663265306122449 f1_macro: 0.4804251731582679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 train loss: tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: tensor(0.3632, device='cuda:0') f1_micro: 0.5706138879570614 f1_macro: 0.473292311306469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 train loss: tensor(0.0445, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: tensor(0.3644, device='cuda:0') f1_micro: 0.5742924528301887 f1_macro: 0.48699049182384774\n",
            "Training Time: 294.93538069725037\n",
            "Training Peak Mem: 2990.59765625\n",
            "Training Params: 10311279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ52F0OYMdsS",
        "outputId": "65942d05-ecdc-471b-e2c2-661b18d13a4b"
      },
      "source": [
        "!pip install git+https://gchhablani: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@github.com/pliang279/multimodal_analysis.git"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://gchhablani:****@github.com/pliang279/multimodal_analysis.git\n",
            "  Cloning https://gchhablani:****@github.com/pliang279/multimodal_analysis.git to /tmp/pip-req-build-86aoy31h\n",
            "  Running command git clone -q 'https://gchhablani:****@github.com/pliang279/multimodal_analysis.git' /tmp/pip-req-build-86aoy31h\n",
            "Requirement already satisfied: appdirs==1.4.4 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (1.4.4)\n",
            "Requirement already satisfied: certifi==2021.5.30 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer==2.0.4 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2.0.4)\n",
            "Requirement already satisfied: click==8.0.1 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (8.0.1)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (0.10.0)\n",
            "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (0.0.12)\n",
            "Requirement already satisfied: idna==3.2 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (3.2)\n",
            "Requirement already satisfied: imageio==2.9.0 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2.9.0)\n",
            "Requirement already satisfied: joblib==1.0.1 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (1.0.1)\n",
            "Requirement already satisfied: kiwisolver==1.3.1 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: lime==0.2.0.1 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib==3.4.3 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (3.4.3)\n",
            "Requirement already satisfied: networkx==2.6.2 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2.6.2)\n",
            "Requirement already satisfied: numpy==1.21.2 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (1.21.2)\n",
            "Requirement already satisfied: packaging==21.0 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (21.0)\n",
            "Requirement already satisfied: Pillow==8.3.1 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (8.3.1)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2.8.2)\n",
            "Requirement already satisfied: PyWavelets==1.1.1 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (1.1.1)\n",
            "Requirement already satisfied: PyYAML==5.4.1 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (5.4.1)\n",
            "Requirement already satisfied: regex==2021.8.3 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2021.8.3)\n",
            "Requirement already satisfied: requests==2.26.0 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2.26.0)\n",
            "Requirement already satisfied: sacremoses==0.0.45 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (0.0.45)\n",
            "Requirement already satisfied: scikit-image==0.18.2 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (0.18.2)\n",
            "Requirement already satisfied: scikit-learn==0.24.2 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (0.24.2)\n",
            "Requirement already satisfied: scipy==1.7.1 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (1.7.1)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl==2.2.0 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2.2.0)\n",
            "Requirement already satisfied: tifffile==2021.8.8 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (2021.8.8)\n",
            "Requirement already satisfied: tokenizers==0.10.3 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (0.10.3)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (1.9.0+cu111)\n",
            "Requirement already satisfied: tqdm==4.62.1 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (4.62.1)\n",
            "Requirement already satisfied: transformers==4.9.2 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (4.9.2)\n",
            "Requirement already satisfied: typing-extensions==3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (3.10.0.0)\n",
            "Requirement already satisfied: urllib3==1.26.6 in /usr/local/lib/python3.7/dist-packages (from mma==0.0.1.dev0) (1.26.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click==8.0.1->mma==0.0.1.dev0) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click==8.0.1->mma==0.0.1.dev0) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvsuJagQGMzJ"
      },
      "source": [
        "import torch, torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import cv2\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from copy import deepcopy"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC1d3nPpYX8G"
      },
      "source": [
        "from mma.analysis.metrics.emap import Emap"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJcNFNH8Zghk",
        "outputId": "1b58408d-13f4-4158-e869-8380383333f7"
      },
      "source": [
        "text_features = None\n",
        "visual_features = None\n",
        "labels = None\n",
        "\n",
        "for batch in validdata:\n",
        "    if text_features is None:\n",
        "        text_features = batch[0].numpy()\n",
        "        visual_features = batch[1].numpy()\n",
        "        labels = batch[2].numpy()\n",
        "    else:\n",
        "        text_features = np.concatenate((text_features, batch[0].numpy()), axis=0)\n",
        "        visual_features = np.concatenate((visual_features, batch[1].numpy()), axis=0)\n",
        "        labels = np.concatenate((labels, batch[2].numpy()), axis=0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsESGGy6YYaJ"
      },
      "source": [
        "dataset = {\n",
        "    'textual_inputs': text_features,\n",
        "    'visual_inputs': visual_features,\n",
        "}"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecLMujgv2Kn5",
        "outputId": "0aca26c6-5651-482a-fc21-0b692a1dd004"
      },
      "source": [
        "text_features.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2608, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrJnXZVEeBuo"
      },
      "source": [
        "model=torch.load(\"best_lf.pt\").cuda()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcQLuYaWhpUz"
      },
      "source": [
        "import gc"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNCDRSz6ebHo"
      },
      "source": [
        "def predictor_fn(visual_inputs, textual_inputs):\n",
        "    model_out  = model([torch.from_numpy(textual_inputs).cuda(), torch.from_numpy(visual_inputs).cuda()])\n",
        "    pred_vqa = F.softmax(model_out, dim = -1).detach().cpu().numpy()\n",
        "    gc.collect()\n",
        "    return pred_vqa"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8RfuF_wf6SN"
      },
      "source": [
        "emap = Emap(predictor_fn, dataset)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrootb-lf9Qc"
      },
      "source": [
        "emap_scores = emap.compute_emap_scores(512)\n",
        "orig_scores = emap.compute_predictions('orig', 512)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSlGtmJvgDkW"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAVqxDJ4wWCJ"
      },
      "source": [
        "assert np.allclose(emap_scores, orig_scores, atol = 1e-6) is False # Check if the values are not equal"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBPtn6SLwWrN"
      },
      "source": [
        "orig_pred_labels = (orig_scores>0.5).astype(np.int32)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLjv5-QewcdW",
        "outputId": "b2945939-4287-42f7-d012-afbcb7170e4c"
      },
      "source": [
        "f1_score(labels, orig_pred_labels, average='micro')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3925538103548575"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNsntbZwxp_C"
      },
      "source": [
        "emap_pred_labels = (emap_scores>0.5).astype(np.int32)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcrxp3_d0SM-",
        "outputId": "28a24df0-07a0-402c-dfe1-0b92076a048e"
      },
      "source": [
        "f1_score(labels, emap_pred_labels, average='micro')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34194491835242496"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}